Em estatística um resultado tem significância estatística se for improvável que tenha ocorrido por acaso. Mais concretamente, a significância está relacionada ao nível de confiança ao rejeitar a hipótese nula quando esta na verdade é verdadeira (erro do tipo I). O nível de significância de um resultado é também chamado de  e não deve ser confundido com o valor p (p-value). Teste de significância é uma expressão cunhada por Ronald Fisher[1] .
O nível de significância não deve ser confundido com probabilidade de significância, uma vez que não é uma probabilidade. Por exemplo, ao fazer um teste com uma média, se fosse possível repetir um número muito grande de amostras para calcular a média, em aproximadamente 5% dessas amostras, seria rejeitada a hipótese nula quando esta é verdadeira. Assim, como em um experimento real, somente é coletada uma amostra, espera-se que esta seja uma da 95% onde a hipótese nula é realmente falsa. Assim tem-se confiança no resultado obtido. Como outro exemplo, ao se calcular um intervalo de confiança 95%, equivalente a um erro Tipo I de 5%, tem-se confiança que o intervalo contêm o parâmetro estimado. No entanto, uma vez que reporta-se um intervalo numérico, o parâmetro populacional desconhecido ou está dentro do intervalo ou fora; não existe uma probabilidade desse intervalo conter o parâmetro.
Outro exemplo: podemos escolher um nível de significância de 5%, e calcular um valor crítico de um parâmetro (por exemplo a média) de modo que a probabilidade de ela exceder esse valor, dada a verdade da hipótese nula, ser 5%. Se o valor estatístico calculado (ou seja, o nível de 5% de significância anteriormente escolhido) exceder o valor crítico, então o resultado é significativo "ao nível de 5%".
Se o nível de significância (ex: 5% anteriormente dado) é menor, o valor é menos provavelmente um extremo em relação ao valor crítico. Deste modo, um resultado que é "significante ao nível de 1%" é mais significante do que um resultado que é significante "ao nível de 5%". No entanto, um teste ao nível de 1% é mais susceptível de padecer do erro do tipo II do que um teste de 5% e por isso terá menos poder estatístico.
Ao divisar um teste de hipóteses, o técnico deverá tentar maximizar o poder de uma dada significância, mas ultimamente tem de reconhecer que o melhor resultado que se pode obter é um compromisso entre significância e poder, em outras palavras, entre os erros de tipo I e tipo II.
É importante ressaltar que os valores p Fisherianos são filosoficamente diferentes dos erros de tipo I de Neyman-Pearson. Esta confusão é infelizmente propagada por muitos livros de estatística.[2]
Análise de "Cluster" (Análise de agrupamento)