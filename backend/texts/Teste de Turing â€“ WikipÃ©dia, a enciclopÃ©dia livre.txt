O Teste de Turing testa a capacidade de uma máquina exibir comportamento inteligente equivalente a um ser humano, ou indistinguível deste. No exemplo ilustrativo original, um julgador humano entra em uma conversa, em linguagem natural, com outro humano e uma máquina projetada para produzir respostas indistinguíveis de outro ser humano. Todos os participantes estão separados um dos outros. Se o juiz não for capaz de distinguir com segurança a máquina do humano, diz-se que a máquina passou no teste. O teste não verifica a capacidade de dar respostas corretas para as perguntas; mas sim o quão próximas as respostas são das respostas dados por um ser humano típico. A conversa é restrita a um canal de texto, como um teclado e uma tela para que o resultado não dependa da capacidade da máquina de renderizar áudio. [2]
O teste foi introduzido por Alan Turing em seu artigo de 1950 "Computing Machinery and Intelligence", que começa com as palavras: "Eu proponho considerar a questão "As máquinas podem pensar?". Já que "pensar" é difícil de definir, Turing preferiu "trocar a pergunta por outra, a qual está relacionada à anterior, e é expressa em palavras menos ambíguas"[3] . A nova pergunta de Turing é: "Há como imaginar um computador digital que faria bem o 'jogo da imitação?"'.[4] Turing cria que esta questão poderia ser respondida. No restante do artigo, ele argumenta contra as principais objeções a proposta que "máquinas podem pensar" [5] o cientista afirmou ainda que, se um computador fosse capaz de enganar um terço de seus interlocutores, fazendo-os acreditar que ele seria um ser humano, então estaria pensando por si próprio.[6]
Muitos eventos que visaram a utilização prática do Teste de Turing já ocorreram, como o Loebner Prize, que acontece anualmente desde 1990 e é dito como o "primeiro teste de Turing"[7] . Há controvérsias se os testes desses eventos são ou não válidos.
Desde 1950, o teste provou ser, ao mesmo tempo, altamente influenciante e criticado, e é um conceito fundamental da filosofia da inteligência artificial. [1] [8]


A questão da inteligência das máquinas possui uma longa história, que está firmemente enraizada na distinção entre as visões dualista e materialista da mente. René Descartes antecipa aspectos do Teste de Turing no seu escrito, de 1637, entitulado Discurso sobre o Método, onde ele escreve:
Quantos autômatos e máquinas de movimento podem ser feitas pela indústria do homem [...] Para que possamos entender facilmente a constituição do ser de uma máquina de modo que possa proferir palavras, e até emitir algumas respostas para ações de natureza corpórea infligidas sobre ela, o que traz uma mudança em seus órgãos; por exemplo, se tocada em uma parte em particular, pergunte-nos o que queremos dizer a ela; se tocada em outra parte, a máquina pode afirmar que está sendo machucada; e assim por diante. Mas ela nunca organiza seu discurso de diversas maneiras, afim de responder apropriadamente a tudo que possa ser dito em sua presença, como até o homem mais simples pode fazer. [9]
Aqui Descartes observa que autômatos são capazes de responder a interações com humanos, mas argumenta que autômatos não podem responder apropriadamente coisas ditas em sua presença do modo que qualquer humano pode. Descartes, assim, prefigura o Teste de Turing quando identifica a insuficiência de respostas linguísticas apropriadas como as que separam humanos de autômatos. Descartes falha em considerar a possibilidade que a insuficiência de respostas linguísticas apropriadas possa ser superada por futuros autômatos e assim não propõe o Teste de Turing, mesmo que ele prefigure seu quadro conceitual e critério.
Denis Diderot formula em seu Pensees Philosophiques um critério de Teste de Turing:
"Se encontrarem um pagagaio que possa responder a tudo, eu iria, sem hesitação, afirmar que este é um ser inteligente."[10]
Isto não significa que ele concorda com isso, mas este já era um argumento comum entre os materialistas da época.
De acordo com o dualismo, a mente é não-física (ou, no mínimo, tem propriedades não-físicas[11] e, portanto, não pode ser explicada puramente em termos físicos. De acordo com o materialismo, a mente pode ser explicada fisicamente, o que deixa aberta a possibilidade de mentes criadas artificialmente.
Em 1936, o filósofo Alfred Ayer considerou a questão filosófica das outras mentes: Como sabemos que outras pessoas tem as mesmas experiências de consciência que nós? Em seu livro, "Linguagem, Verdade e Lógica", Ayer sugere um protocolo para distinguir um homem consciente de uma máquina inconsciente: "O único motivo que possa ter para afirmar que um objeto que parece consciente não passa de um manequim ou uma máquina é que ele falha em satisfazer um dos testes empíricos pelos quais a presença ou abstinência de consciência é determinada. [12] (Esta sugestão é semelhante ao Teste de Turing, mas não certo se Ayer era familiar com Turing.) Em outras palavras, uma coisa não é consciente se falhar no teste de consciência.'
Pesquisadores no Reino Unido exploraram a "inteligência artificial" por dez anos antes da fundação da IA como campo de pesquisa, em 1956. [13] Este era um tema comum entre os membros do Ratio Club, um grupo informal de pesquisadores britânicos de cibernética e eletrônica, entre os quais Alan Turing, a quem o teste foi nomeado.[14]
Turing, particularmente, abordou a noção de inteligência de máquinas desde, pelo menos, 1941[15] e uma das mais antigas menções de "inteligência computacional" foi feita por ele, em 1947.[16] No relatório de Turing, "Intelligent Machinery", ele investigou "a questão se é possível ou não máquina apresentarem comportamento inteligente"[17] e, como parte da investigação, propor o que pode ser considerado o precursor do que seria o Teste de Turing:
Não é difícil de conceber uma máquina de papel que vai jogar um jogo não muito ruim de xadrez.[18] Agora, pegue três homens para um experimento. A,B e C. A e C devem ser péssimos xadrezistas, B é o operador da máquina de papel. ...Duas salas são usadas com algum mecanismo para comunicação de movimentos, e uma partida é disputada por C e A ou, exclusivamente, a máquina de papel. C pode achar difícil afirmar com quem ele está jogando.[19]
Em um artigo posterior, Turing sugere um formulação alternativa "equivalente" envolvendo um julgador conversando somente com um computador e um homem. [20] Apesar de nenhuma dessas formulações correspondem a versão do Teste de Turing como é conhecido hoje, ele propôs uma terceira versão em 1952. Nesta versão, discutida por Turing na rádio BBC, um juri indaga um computador que tem o papel de fazer uma parte considerável do júri acreditar que estão se comunicando com um homem.[21]
O artigo de Turing considerava nove dúvidas putativas, as quais incluiam todos os principais argumentos com a inteligência artificial que foram levantados desde a publicação do artigo "Computing Machinery and Intelligence".
Em 1966, Joseph Weizenbaum criou um programa que aparentava passar no Teste de Turing. O programa, denominado ELIZA, trabalhava examinando comentários digitados por um usuário procurando por palavras-chave. Se uma palavra-chave era encontrada, a regra que transforma o comentário do usuário era aplicada e a sentença resultante retornada. Se nenhuma palavra-chave era encontrada, ELIZA retornava uma resposta genérica ou repetida o retorno do comentário anterior.[22] Além disso, Weizenbaum desenvolveu ELIZA de modo a replicar o comportamento de um psicoterapeuta Rogeriano, permitindo ELIZA, assim, ser "quase que livre para assumir uma postura de desconhecimento total do mundo real."[23] Com essas técnicas, o programa de Weizenbaum foi capaz de fazer com que pessoas acreditassem que estavam falando com um ser humano, ao ponto de, para algumas pessoas ser "muito difícil de convencê-las que ELIZA [...] não é um humano."[23] Assim, ELIZA foi considerada por alguns como um programa (talvez o primeiro) a passar no Teste de Turing, [23] [24] , apesar destas visões serem altamente controvérsias.(veja abaixo).
Em 1980, John Searle divulgou o artigo denominado Minds, Brains, and Programs, onde propunha o experimento mental "Sala chinesa" e argumentava que o Teste de Turing não poderia determinar se uma máquina pensava. Searle notou que software (como ELIZA) poderia passar no Teste de Turing simplesmente manipulando símbolos que ele não entendia. Sem entendimento, eles não poderiam ser descritos como "pensantes" no mesmo sentido que as pessoas são. Assim, Searle conclui, que o Teste de Turing não pode provar se uma máquina pode pensar.[25] O argumento de Searle foi altamente criticado,[26] mas o argumento também foi endossado.[27]
Argumentos como o de Searle e que outros trabalham sobre a filosofia da mente desencadearam nas décadas de 1980 e 1990 um debate mais intenso sobre a natureza da inteligência, a possibilidade de máquina inteligentes e o valor do Teste de Turing.[28]
O Prêmio de Loebner promove, desde novembro de 1991, uma plataforma anual para demonstrações práticas do Teste Turing.[29] Ele é assinado por Hugh Loebner.O Cambridge Center for Behavioral Studies em Massachusetts,Estados Unidos organizou os prêmios até 2003. Como Loebner disse, uma das razões para a criação da competição é o avanço da pesquisa em IA e também porque ninguém conseguiu trilhar um caminho para implementação do Teste de Turing, apesar dos 40 anos de discussão do tema.[30]
A primeira disputa do Prêmio de Loebner ocorreu em 1991 e levou a renovação da discussão sobre viabilidade do Teste de Turing e o valor em buscá-lo, na mídia popular [31] e na academia .[32] O primeiro concurso foi vencido por um programa sem nenhum tipo de IA que foi capaz de enganar interrogadores. Isto destacou várias fraquezas do Teste de Turing (discutido em abaixo): O vencedor venceu, pelo menos em parte, porque foi capaz de "imitar os erros de digitação recorrentes em humanos";[31] os interrogadores foram facilmente enganados; [32] e outro pesquisadores de IA crêem que o teste é somente uma distração de pesquisas mais promissoras.[33]
Os prêmios de prata (somente texto) e de ouro (áudio e vídeo) nunca foram vencidos. Entretanto, a competição vem premiando todos os anos com medalhas de bronze programas que, a opinião dos julgadores, demonstram um comportamento em conversar "mais humano". Artificial Linguistic Internet Computer Entity (A.L.I.C.E.) venceu a medalha de bronze por três anos recentemente (2000,2001,2004). O programa de aprendizado artificial Jabberwacky venceu em 2005 e 2006.[34]
O vencedores dos testes de conversação normalmente são programas de chatterbot ou Entidades de conversação artificial (ACE). Nos primeiros anos, as regras de conversação era restritas: Cada máquina e humano conversavam sobre um só tópico, assim os interrogadores eram restritos a uma linha de questionamento por interação com o programa. A regra de conversa restrita foi extinta em 1995. A duração das interações entre o interrogador e a máquina varia entre as edições do prêmio. Em 2003, na Universidade de Surrey, cada interrogador era permitido interagir por 5 minutos com a máquina, entidade ou humano-escondido. Entre 2004 e 2007, o tempo de interação foi estendido para 20 minutos. Em 2008, voltou-se a usar 5 minutos porque o organizador, Kevin Warwick, e o coordenador, Huma Shah, consideraram que esta deve ser a duração de qualquer teste, como Turing disse em seu artigo de 1950: "... fazendo a correta identificação após 5 minutos de questionamentos".[35] Eles sentiram que o tempo usado em 2007 e 2008 era inapropriado para o estado da conversação artificial[36] É irônico que o vencedor de 2008, Elbot, não imita um humano; sua personalidade é a de um robô, apesar de Elbot ter enganado três juízes humanos. [37]
Durante a competição de 2009, ocorrida em Brighton, Reino Unido, a restrição de tempo foi de 10 minutos para cada rodada, 5 minutos de conversa com um humano e 5 minutos de conversa com um programa. Isto serviu para testar a leitura alternativa da predição de Turing, com interacção de 5 minutos com o computador. Para a competição de 2010, o tempo de interação foi, novamente, aumentado para 25 minutos. [38]
Saul Traiger argumento que há ao menos três versões para o Teste de Turing, duas das quais são apresentadas em "Computing Machinery and Intelligence" e outra é descrita por ele como "Interpretação padrão." [39] Há um debate sobre o fato da "interpretação padrão" ser descrita por Turing ou, em vez disso, baseado em uma interpretação errada do artigo, essas três versões não são equivalentes,[39] e suas forças e fraquezas são distintas.[40]
Huma Shah aponta que o próprio Turing estava interessado na questão do pensamento de máquinas e estava propondo um método simples testar se isto é possível: através de sessões de perguntas e respostas entre humanos e máquinas.[41] Shah argumenta que o jogo de imitação proposto por Turing poderia ser praticado de dois modos: a) testes de interrogamento um-a-um e b)comparação simultânea de uma máquina com um homem, ambos sendo questionados em paralelo por um interrogador.[42] Já que o Teste de Turing é um teste de indistinção em capacidade de perfomace, a versão verbal generaliza naturalmente toda a capacidade de perfomace humana, tanto verbal como não-verbal (robótica). [43]
O jogo original, proposto por Turing, descreve uma simples interação entre três jogadores. Jogador A é um homem, jogador B é uma mulher e o jogador C (que faz o papel de interrogador) pode ter qualquer sexo. Neste Jogo de Imitação, o jogador C não é capaz de ver nenhum dos outros participante e só pode comunicar-se com eles através de mensagens escritas. Fazendo perguntas a A e B, o jogador C tenta determinar qual deles é homem e qual é mulher. O papel do jogador A é de levar o interrogador a fazer a decisão errada, enquanto o jogador B tenta ajudar o interrogador.[1]
Sterret referencia este como o "Teste do Jogo de Imitação Original"[44] Turing propôs que o papel do jogador A fosse feito por um computador, ou seja, fazer o papel do homem e levar o interrogador ao erro. O sucesso do computador seria determinado por uma comparação com o resultado do jogo quando o jogador A é um homem. Turing disse que se "o interrogador decidir incorretamente tão frequentemente em ambos os cenários, com um computador ou com um homem.",[45] pode-se dizer que o computador é inteligente.
A segunda versão apareceu em um artigo posterior de Turing, em 1950. Similarmente ao Teste do Jogo de Imitação Original, o papel do jogador A é feito por um computador. Entretanto, o papel do jogador B é feito por um homem, ao invés de uma mulher.
"Fixemos nossa atenção em um computador em particular, digamos C. É verdade que, modificando este computador para que tenha um capacidade de memória suficiente, com um aumento substancial na sua velocidade de processamento, e provendo-o com um programação adequada, C pode desempenhar satisfatoriamente o papel de A no jogo da imitação, sendo a parte B desempenhada por um homem?"[45]
Nesta versão, tanto o jogador A (o computador) tanto o B estão tentando enganar o interrogador.
O entendimento comum diz que a proposta do Teste de Turing não é de que, especificamente, em computador é capaz de enganar um interrogador, levando-o a acreditar que está lidando com um humano, mas que um computador é capaz de imitar um humano.[1] Enquanto há alguma disputa sobre a interpretação proposta por Turing = Sterrett acreditava que esta era a correta[44] e deste modo, funde as duas versões em uma, enquanto outros, como Traiger, não o fazem[39] - isto, não obstante, levou ao que é visto como "interpretação padrão." Nesta versão, o jogador A é um computador e o jogador B uma pessoa de qualquer sexo. O papel de interrogador não é determinar quem é homem ou mulher, mas quem é o computador e quem é o humano.[47] A questão fundamental com a interpretação padrão é que o interrogador não pode diferenciar uma resposta dada por uma máquina da dada por um humano. Há questões de duração do teste, mas a interpretação padrão generaliza essa limitação para algo que seja razoável.
Controvérsia surgiu sobre as formulações alternativas do Teste de Turing.[44] Sterrett argumenta que dois testes distintos podem ser extraídos de seu artigo de 1950 e que, o comentário de "ritmo" de Turing, eles não são equivalentes. O teste que emprega o jogo e compara frequências de sucesso é referenciado como o "Teste do Jogo de Imitação Original", enquanto o teste que consiste de um juíz humano conversando com um humano e uma máquina é referenciado como "Teste de Turing Padrão", notando que Sterrett equivale este com a "interpretação padrão", em vez da segunda versão do jogo de imitação. Sterrett concorda que o Teste de Turing Padrão (TTP) tem problemas que seus críticos citam, mas sente que, em contraste, o Teste do Jogo de Imitação Original (TJIO) é imune a muitas destas, devido a uma diferença crítica: Diferentemente do TTP, o TIJO não usa como critério a similaridade com a perfomace humana, apesar de empregar o desempenho humano em estabelecer um critério para a inteligência da máquina. Um homem pode falhar no TIJO, mas argumenta-se que é uma virtude que uma falhas em um teste de inteligência indica um falta de desenvoltura: O TIJO requer uma desenvoltura associada com inteligência e não simplesmente "simulação do comportamento humano de conversação." A estrutura geral do TIJO pode até ser usada com versões não-verbais dos jogos de imitação. [48]
Ainda há outro autores[49] que interpretaram que Turing propôs o jogo da imitação como um teste em si, sem especificar como levar em consideração a declaração de Tuirng que o teste que eles propôs usa a versão da festa do jogo de imitação é baseada em um critério de comparação de frequência de sucesso naquele jogo de imitação, ao invés de uma capacidade de sucesso em uma rodada do jogo.
Saygin sugeriu que talvez o jogo original é um meio de propor um design experimental menos tendencioso, já que ele esconde a participação do computador.[50] O jogo da imitação também inclui um "hack social" não encontrado na interpretação padrão, visto que o jogo requere um humano masculino e um computador, jogando com a intenção de demonstrar que são alguém que não são.
Uma peça crucial de qualquer laboratório de testes deve ser a sala de controle. Turing nunca deixou claro, em seus testes, se o interrogador estava ciente que um dos participantes é um computador. Entretanto, se há uma máquina capaz de passar no Teste de Turing, pode-se assumir que um teste duplo-cego é necessário.
Para retornar ao Jogo de Imitação Original, em declara que somente o jogador A deve ser substituído por uma máquina, sem que o jogador C esteja ciente disto.[45] QUando Colbu, FD Hilf, S Weber e AD Kramer testaram PARRY, eles assumiram que os interrogadores não sabiam que um ou mais dos entrevistados era um computador.[51] Enquanto Ayse Saygin, Peter Swirski[52] , e outros destacaram, isto faz uma grande diferença na implementação e resultado do teste.[1] Um estudo experimental observou "Gricean maxim violations" usando transcrições de Loebner um-a-um (interlocutor escondido do interrogador) Premiado em competições de IA entre 1994-1999, Ayse Saygin encontrou uma diferença substancial entre as respostas dos participantes que sabiam e que não sabiam sobre o envolvimento de computadores.[53]
Huma Shah e Kevin Warwick, que organizaram o 2008 Loebner Prize na Reading University, mostraram que o conhecimento do envolvimento de computadores não fez uma diferença significativa na decisão dos juízes. Juízes não foram informados explicitamente da natureza de seus pares. Juízes capazes de distinguir humanos de computadores, incluindo quando eles eram postos com dois humanos ou duas máquinas. Erros de grafia revelaram os humanos; máquinas foram identificadas pela 'velocidade de resposta' e expressões mais longas.[37]
O poder e apelo do teste de Turing vem de sua simplicidade. A filosofia da mente, psicologia e a moderna neurociência não conseguiram prover definições de "inteligência" e "pensamento" que sejam suficientemente precisas e gerais para serem aplicadas à máquinas. Sem estas definições, as questões centrais da filosofia da inteligência artificial não podem ser respondidas. O teste de Turing, apesar de sua imperfeição, ao menos provê algo que pode ser medido. Portanto, é uma solução pragmática para uma difícil questão filosófica.
O formato do teste permite que o interrogador dê à máquina uma vasta variedade de tarefas intelectuais. Turing escreveu que "o método de questão e resposta parece ser adequado para introduzir quase que qualquer um dos campos do pensamento humano que desejarmos."[54] John Haugeland ainda diz que "o entendimento das palavras não é suficiente; você tem que entender o "tópico" também."[55]
Para passar em um Teste de Turing bem planejado, a máquina deve usar de linguagem natural,razão, ter conhecimento e aprendizado. O teste pode ser expandido para incluir input de vídeo, assim como uma escotilha pela qual objetos pode ser passados: Isto forçaria a máquina a possuir visão e robótica. Juntos, estes representam quase que a totalidade dos principais problemas que a pesquisa de IA gostaria de resolver.[56]
Turing não declarou explicitamente que o Teste de Turing poderia ser usado como medida de inteligência. Ele queria prover uma clara e compreensível alternativa para a palavra "pensar", pela qual ele poderia usar para responder ao criticismo da possibilidade de "máquinas pensantes" e para sugerir meio que a pesquisa poderia desenvolver-se.
Não obstante, o Teste de Turing foi proposto para uma medida da "capacidade de pensamento" e "inteligência" de uma máquina. A proposta foi recebida com criticismo tanto por filósofos como por cientistas da computação. Assume-se que um interrogador pode determinar se uma máquina está "pensando" comparando seu desempenho com o comportamento humano. Todo elemento dessa assumpção pode ser questionada: a confiança no julgamento do interrogador, o valor da comparação simplesmente do comportamento e o valor de comparar uma máquina com um homem. Por causa disso e de outras considerações, alguns pesquisadores de IA questionaram a relevância do teste no seu campo.
O Teste de Turing não testa diretamente se um computador se comporta de forma inteligente - ele teste somente se um computador se comporta como um humano. Já que o comportamento humano e comportamento inteligente não são exatamente a mesma coisa, o teste de falhar como medida de inteligência de duas formas:
O Teste de Turing está preocupado estritamente com como o objeto "age" - o comportamento externo da máquina. Neste aspecto, ele toma as abordagens do Behaviorismo ou do funcionalismo para estudar inteligência. O exemplo de ELIZA sugere que uma máquina que passa no teste pode ser capaz de simular o comportamento de conversa humana seguindo um simples (porém grande) lista de regras mecânicas, sem nenhum tipo de pensamento.
John Searle argumentou que comportamento externo não pode ser usado para determinar se uma máquina está "realmente" pensando ou simplesmente "simulando pensamento".[25] Seu argumento da sala chinesa tem a intenção de mostrar que, mesmo o Teste de Turing sendo uma boa definição operacional de inteligência, isto pode não indicar que a máquina tem uma mente, consciência ou intenção. (Intenção é um termo filosófico para poder de pensamento ser "sobre" algo.)
Turing antecipou esta linha de criticismo no seu artigo original, [61] escrevendo: {{quote|Eu não desejo dar uma impressão que eu penso que não há mistério sobre a consciência. Há, por exemplo, um tipo de paradoxo conectado com qualquer tentativa de localizá-la. Mas eu não penso que esses mistérios necessariamente precisam ser resolvidos para que possamos responder a questão desenvolvida neste artigo.[62]
Na prática, os resultados do teste podem ser facilmente dominados não pela inteligência do computador, mas pelas atitudes, habilidades e inocência do questionador.
Turing não especifica habilidades ou conhecimento necessários para o interrogador na descrição do teste, mas ele usa o termo "interrogador comum": "[o] interrogador comum não deve ter mais de 70% de chances de fazer a identificação correta após 5 minutos de conversação".[35]
Shah & Warwick (2009b) mostra que experts podem ser enganados, e que a estratégia do interrogador, "poder" vs "solidariedade" afeta a correta identificação, o segundo sendo melhor para o sucesso.
Programas chatterbot como ELIZA enganaram repetidamente pessoas desavisadas, fazendo-as acreditarem estar falando com um humano. Nestes casos, o "interrogador" não está ciente da possibilidade de estarem interagindo com um computador. Para parecer humano com sucesso, não há necessidade da máquina ter qualquer inteligência, somente uma lembrança superficial do comportamento humano.
Os competidores dos primeiros prêmios Loebner usavam interrogadores "não-sofisticados" que era facilmente enganados pelas máquinas.[32] Desde 2004, os organizadores do prêmio Leobner usaram filósofos, cientistas da computação, jornalistas como interrogadores. Não obstante, alguns destes interrogadores foram enganados pelas máquinas. [63]
Micheal Shermer aponta que humanos constantemente escolhem considerar objetos não-humanos como humanos sempre que tem a chance, um erro chamado falácia antropomórfica: Eles falam com seus carros, atribuem desejo e intenção a forças da natureza (e.g., "natureza abomina o vácuo"), e adoram o Sol como um ser humanificado com inteligência. Se o Teste de Turing é aplicado a objetos religiosos, Shermer argumenta, então, que estátuas inanimadas, rochas e lugares passaram o teste por toda a história.[carece de fontes?] Esta tendência humana pelo antropomorfismo efetivamente diminui o limite para o Teste de Turing, ao menos que o interrogador esteja treinado para evitá-la.
Os principais pesquisadores de IA argumenta que a tentativa de passar no Teste de Turing é simplesmente uma distração, não uma pesquisa frutífera.[64] De fato, o Teste de Turing não é o foco de muitas pesquisas acadêmicas ou comerciais - como Stuart Russell e Peter Norvig escreveram: "Pesquisadores de IA dedicaram pouca atenção a tentativas de passar no Teste de Turing."[65] Por diversas razões.
Primeiro, há maneiras mais fáceis de testar seus programas. Boa parte da pesquisa atual na área de IA está focada em objetivos modestos e específicos, como planejamento automatizado, reconhecimento de objetos ou logística. Para testar a inteligência de programas nestes problemas, pesquisadores de IA simplesmente os dão tarefas diretamente, ao invés de ir através do método indireto de postar uma pergunta em uma sala de chat populada com computadores e pessoas.
Segundo, criar simulações semelhantes a vida de humanos é um problema difícil por si só que não precisa ser resolvido para alcançar os objetivos básicos de pesquisa de IA. Personagens que atuem como humanos por ser interessantes em um trabalho de arte, um video game ou uma interface de usuário sofisticada, mas eles não são parte da ciência de criar máquina inteligentes, ou seja, máquinas que resolvam problemas usando inteligência. Russell e Norvig sugerem uma analogia com a história do voo: Aviões são testados para quão bem podem voar, mas não são comparados como aves. "Textos de engenharia aeronáutica", eles escrevem, "não definem objetivos em seus campos como 'fazer máquina que voam assim como aves, para que possam enganar outras aves'"[66]
Turing nunca teve a intenção que seu teste fosse usado como um meio prático de medir a inteligência de programas de IA; eles pretendia prover um claro e entendível exemplo para contribuir com a discussão da filosofia da inteligência artificial.[67] John McCarthy observa que a filosofia da IA é "improvável que afete a pesquisa prática de IA que a filosofia da ciência em geral tem sobre a prática científica."[68]