A Arquitetura de von Neumann - de John von Neumann (pronunciado Nôimánn) - é uma arquitetura de computador que se caracteriza pela possibilidade de uma máquina digital armazenar seus programas no mesmo espaço de memória que os dados, podendo assim manipular tais programas. Esta arquitetura é um projeto modelo de um computador digital de programa armazenado que utiliza uma unidade de processamento (CPU) e uma de armazenamento ("memória") para comportar, respectivamente, instruções e dados.[1] [2] [3] [4] [5] [6]

A máquina proposta por Von Neumann reúne os seguintes componentes:
Todos os elementos dessa arquitetura são alinhados da estrutura hardware do CPU, assim o sistema pode realizar todas as suas atividades sem apresentar erros no desempenho. Von Neumann é continuamente influenciados pela evolução tecnológica, tendo peças mais modernas inseridas. Cada um dos elementos apresentados é realizado à custa de componentes físicos independentes, cuja implementação tem variado ao longo do tempo, consoante a evolução das tecnologias de fabricação, desde os relés electromagnéticos, os tubos de vácuo (ou válvulas), até aos semicondutores, abrangendo os transistores e os circuitos eletrônicos integrados, com média, alta ou muito alta densidade de integração (MSI - medium scale, LSI - large scale, ou VLSI - very large scale integration), medida em termos de milhões transistores por pastilha de silício.
As novas interações entre os elementos exibem tempos típicos que também têm variado ao longo do tempo, consoante as tecnologias de fabricação. Atualmente, as CPUs processam instruções sob controlo de relógios cujos períodos típicos são da ordem de 1 nanosegundo, ou seja,  segundos. As memórias centrais têm tempos típicos de acesso da ordem da dezena de nanosegundos. As unidades de entrada e saída exibem tempos típicos extremamente variáveis, mas que são tipicamente muito superiores à escala do nanosegundo. Por exemplo, os discos rígidos exibem tempos da ordem dos milissegundos (milésimo de segundo, ). Outros dispositivos periféricos são inertes, a não ser que sejam ativados por utilizadores humanos. Por exemplo, ao se fazer "copy and paste" nao se-percebe nada do que foi descrito acima, pois um teclado só envia informação para o computador após serem pressionada as devidas teclas. Assim, este dispositivo se comunica com a CPU eventualmente e, portanto, exibe tempos indeterminados.
O modelo (ou arquitetura) de Von Neumann foi concebido a partir de 1946, quando John von Neumann e sua equipe desenvolveram um novo projeto de “computador de programa armazenado”. Projetado pela IAS (Princeton Institute for Advanced Studies), este computador foi largamente difundido, influenciando muitos projetos subsequentes de outras máquinas.


As primeiras máquinas de computação tinham programas fixos. Alguns computadores muito simples ainda usam este projeto, quer para fins de simplicidade ou de formação. Por exemplo, uma calculadora de mesa (em princípio) é um programa de computador fixo. Ele pode fazer a matemática básica, mas não pode ser usado como um processador de texto ou um emulador de console de videogame. Alterar o programa de uma máquina de programa fixo exige religação, reestruturação ou reprojetar a máquina. Os primeiros computadores não eram tão "programados", como eles foram "desenhados". Era um processo trabalhoso, começando com fluxogramas e cédulas de papel, seguido de desenhos detalhados de engenharia e, em seguida o processo muitas vezes penoso fisicamente de religação e reconstrução da máquina. Podendo levar três semanas para criar um programa no ENIAC e começar a trabalhar.[1]
A ideia do computador de programa armazenado, mudou tudo isso: um computador que pelo projeto inclui um conjunto de instruções e pode armazenar na memória um conjunto de instruções (programa) que detalha o cálculo. Um projeto de programa armazenado também permite que os programas possam se modificar durante a execução. Uma motivação precoce para uma instalação desse tipo foi a necessidade de um programa para incrementar ou modificar a porção do endereço das instruções, o que tinha que ser feito manualmente em projetos adiantados. Isto tornou-se menos importante quando registradores de índice e endereçamento indireto foram as características usuais da arquitetura da máquina. Código de Automodificação foi amplamente caído em desuso, já que normalmente é difícil de entender e depurar, bem como sendo ineficiente em pipelining processador moderno, e esquemas de cache.
Em grande escala, a capacidade de tratar as instruções como os dados é o que faz montadores, compiladores e outras ferramentas de programação automatizada possíveis. Pode-se "escrever programas que escrevem programas." Em uma escala menor, instruções de I / O da máquina intensiva, como o BitBlt primitivos usados para modificar imagens em um display bitmap. Foi mostrado posteriormente que estas instruções podem ser implementadas de forma eficiente por "na compilação fly" ("just-in-time de compilação) de tecnologia, por exemplo, geração de código de programas, uma forma de código de auto-modificação que se manteve popular.
Há desvantagens para a concepção de von Neumann. Além do gargalo de von Neumann descrito abaixo, alterar o programa pode ser bastante prejudicial, quer por acidente ou design. Em alguns projetos simples computador de programa armazenado, um programa com defeito pode danificar outros programas, ou o sistema operacional, possivelmente levando a uma pane no computador. Proteção de memória e outras formas de controle de acesso.
O matemático Alan Turing, que tinha sido alertado para um problema de lógica matemática pelas palestras de Max Newman na Universidade de Cambridge, escreveu um artigo em 1936 intitulado On Computable Numbers, com um aplicativo para o Entscheidungsproblem, que foi publicado nos Anais da Sociedade Matemática de Londres. Nela, ele descreveu uma máquina hipotética que ele chamou de "máquina de computação universal", e que agora é conhecida como a "máquina de Turing universal". A máquina hipotética tinha um armazenamento infinito (memória, na terminologia de hoje instruções e dados). O engenheiro alemão Konrad Zuse, independentemente escreveu sobre este conceito em 1936. John von Neumann tornou-se familiarizado com Turing, quando ele era professor visitante na Universidade de Cambridge em 1935 e também durante o ano que Turing passou na Universidade de Princeton, em 1936-1937.
Von Neumann estava envolvido no Projeto Manhattan no Los Alamos National Laboratory, que exigiu enormes quantidades de cálculo. Isso o levou para o projeto ENIAC, no verão de 1944. Lá ele se juntou ao debate em curso sobre a concepção deste computador de programa armazenado, o EDVAC. Como parte desse grupo, ele se ofereceu para escrever uma descrição do mesmo. O termo "arquitetura de von Neumann" surgiu a partir de uma publicação de von Neumann, o primeiro esboço de um relatório sobre o EDVAC datado de 30 de junho de 1945, que incluía ideias de Eckert e Mauchly. O esboço estava inacabado quando seu colega Herman Goldstine que circulou somente com o nome de von Neumann sobre ele, para a consternação de Eckert e Mauchly. O documento foi lido por dezenas de colegas de von Neumann nos Estados Unidos e Europa, influenciando a próxima rodada de modelos de computador.
Ambas publicações de von Neumann e Turing descreveram um programa armazenado para computadores, mas a publicação de von Neumann alcançou maior circulação e a arquitetura do computador que ele expôs ficou conhecida como a "arquitetura de von Neumann". Von Neumann foi, então, o criador da arquitetura de programa armazenado, mas Jack Copeland considera que é "historicamente inadequado" referir-se a eletrônica de programa armazenado e computadores digitais como "máquinas de von Neumann"
O canal de transmissão de dados entre a CPU e a memória leva ao gargalo de von Neumann, a troca de dados limitada (taxa de transferência) entre a CPU e a memória em relação à quantidade de memória. Na maioria dos computadores modernos, a troca de dados entre o processador e a memória é muito menor do que a taxa com que o processador pode trabalhar. Isso limita seriamente a velocidade eficaz de processamento, principalmente quando o processador é exigido para realizar o processamento de grandes quantidades de dados. A CPU é constantemente forçada a esperar por dados que precisam ser transferidos para, ou a partir da, memória. Como a velocidade da CPU e o tamanho da memória têm aumentado muito mais rapidamente que a taxa de transferência entre eles, o gargalo se tornou mais um problema, um problema cuja gravidade aumenta com cada geração de CPU.[7]
O termo "gargalo de von Neumann" foi cunhado por John Backus em sua palestra Award 1977 ACM Turing. Segundo Backus:
Certamente deve haver uma maneira menos primitiva de se fazer grandes alterações na memória, do que empurrando um grande número de palavras, de um lado a outro, do gargalo de von Neumann. Não é somente um gargalo literal para o tráfego de dados, mas, o mais importante, é um gargalo intelectual que nos tem mantido atados a um pensamento de "uma palavra por vez" em vez de encorajar-nos a pensar em termos unidades conceituais maiores. Assim, a programação é basicamente o planejamento e detalhamento do enorme tráfego de palavras através do gargalo de von Neumann e grande parte desse tráfego não diz respeito aos dados propriamente ditos, e sim a onde esses dados são encontrados.[8]
O problema de desempenho pode ser aliviado (até certo ponto) por diversos mecanismos. Colocando uma memória cache entre o processador e a memória principal, proporcionando caches separados com os caminhos de acesso separado para dados e instruções (a chamada arquitetura Harvard Modificada), utilizando um algorítmo preditor de salto e lógica. O problema também pode ser contornado usando um pouco de computação paralela, por exemplo a arquitetura NUMA, esta abordagem é geralmente utilizada em supercomputadores.
A Primeira Ideia (primeiro rascunho - First Draft) descrevia um design de computador que foi usado por muitas universidades e corporações para construir seus computadores. [9] Dentre esses computadores, somente o ILLIAC e o ORDVAC possuíam instruções compatíveis.

